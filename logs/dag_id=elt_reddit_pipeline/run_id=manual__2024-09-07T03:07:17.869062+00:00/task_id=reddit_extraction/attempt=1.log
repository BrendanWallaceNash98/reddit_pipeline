[2024-09-07T03:07:18.466+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-09-07T03:07:18.481+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: elt_reddit_pipeline.reddit_extraction manual__2024-09-07T03:07:17.869062+00:00 [queued]>
[2024-09-07T03:07:18.486+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: elt_reddit_pipeline.reddit_extraction manual__2024-09-07T03:07:17.869062+00:00 [queued]>
[2024-09-07T03:07:18.487+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-09-07T03:07:18.493+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-09-07 03:07:17.869062+00:00
[2024-09-07T03:07:18.496+0000] {standard_task_runner.py:64} INFO - Started process 53 to run task
[2024-09-07T03:07:18.499+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'elt_reddit_pipeline', 'reddit_extraction', 'manual__2024-09-07T03:07:17.869062+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmp6ltr14hl']
[2024-09-07T03:07:18.500+0000] {standard_task_runner.py:91} INFO - Job 5: Subtask reddit_extraction
[2024-09-07T03:07:18.527+0000] {task_command.py:426} INFO - Running <TaskInstance: elt_reddit_pipeline.reddit_extraction manual__2024-09-07T03:07:17.869062+00:00 [running]> on host 560ae0bca213
[2024-09-07T03:07:18.570+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Brendan Wallace Nash' AIRFLOW_CTX_DAG_ID='elt_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-09-07T03:07:17.869062+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-09-07T03:07:17.869062+00:00'
[2024-09-07T03:07:18.570+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-09-07T03:07:18.577+0000] {logging_mixin.py:188} INFO - connected to reddit
[2024-09-07T03:07:19.864+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '', 'author_fullname': 't2_bnnnwrv8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'is_gallery': True, 'title': 'Any tools to make these diagrams ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 75, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'03yn5xy1p5nd1': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 58, 'x': 108, 'u': 'https://preview.redd.it/03yn5xy1p5nd1.jpg?width=108&crop=smart&auto=webp&s=361eab3d99cb36b579e8bb636b25e976044ecf1e'}, {'y': 117, 'x': 216, 'u': 'https://preview.redd.it/03yn5xy1p5nd1.jpg?width=216&crop=smart&auto=webp&s=5d1ac96ac4d014f2625df8bdbd8c018a74fe94a1'}, {'y': 173, 'x': 320, 'u': 'https://preview.redd.it/03yn5xy1p5nd1.jpg?width=320&crop=smart&auto=webp&s=dc23cbe5bee78cec85d4b510fd6026fb0df167ad'}, {'y': 347, 'x': 640, 'u': 'https://preview.redd.it/03yn5xy1p5nd1.jpg?width=640&crop=smart&auto=webp&s=7901bfbd1a25fe0cac0f2ced13d4fa8d9711381e'}], 's': {'y': 408, 'x': 752, 'u': 'https://preview.redd.it/03yn5xy1p5nd1.jpg?width=752&format=pjpg&auto=webp&s=af873d227992d3c7a84fcc877d3d60e6fc3b38e6'}, 'id': '03yn5xy1p5nd1'}, 'vjzsjr32p5nd1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 50, 'x': 108, 'u': 'https://preview.redd.it/vjzsjr32p5nd1.png?width=108&crop=smart&auto=webp&s=10a2a453f27cd2babfaf2bcd41356edb6fa80ad2'}, {'y': 100, 'x': 216, 'u': 'https://preview.redd.it/vjzsjr32p5nd1.png?width=216&crop=smart&auto=webp&s=fe137f0c6b77a3bc1c30247b87123f9d943295bf'}, {'y': 148, 'x': 320, 'u': 'https://preview.redd.it/vjzsjr32p5nd1.png?width=320&crop=smart&auto=webp&s=2bda9f3b26d4ebcbcf952236ba210c6b4561212a'}, {'y': 296, 'x': 640, 'u': 'https://preview.redd.it/vjzsjr32p5nd1.png?width=640&crop=smart&auto=webp&s=615be9432fb8e1cd03a142a5985e6b62be3b065a'}], 's': {'y': 377, 'x': 813, 'u': 'https://preview.redd.it/vjzsjr32p5nd1.png?width=813&format=png&auto=webp&s=6ff66a22398d1a0a333325788a09aa181a395e03'}, 'id': 'vjzsjr32p5nd1'}}, 'name': 't3_1faatb8', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.98, 'author_flair_background_color': None, 'ups': 157, 'domain': 'reddit.com', 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'gallery_data': {'items': [{'caption': '', 'media_id': '03yn5xy1p5nd1', 'id': 514863331}, {'caption': '', 'media_id': 'vjzsjr32p5nd1', 'id': 514863332}]}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 157, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/mQB849gL4gy6YHgYvl3oQamFENX5SgZnma_hd0Few4M.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1725614227.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'total_awards_received': 0, 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.reddit.com/gallery/1faatb8', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1faatb8', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Zyad070'), 'discussion_type': None, 'num_comments': 61, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faatb8/any_tools_to_make_these_diagrams/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/gallery/1faatb8', 'subreddit_subscribers': 210878, 'created_utc': 1725614227.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.868+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I am working as a DE with 2 YOE in healthcare making just over 100k. There are opportunities to grow but employer is stingy with raise and career ladder is not clear after senior. However, work life balance is great - I am fully remote, rarely ever have to work over time and no micromanagement. Also no lay offs so far.\n\nI do often wonder if I could learn more from working for another company with big data and more modern tech stack. I am worried that the longer I stay here I might miss out on improving my technical skills and not be up to date with the job market. At the same time, I love having free time for my hobbies and having a low stress job...\n\n\n\n', 'author_fullname': 't2_5alnzkja', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Should I jump ship?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faapqa', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 46, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 46, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725613751.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I am working as a DE with 2 YOE in healthcare making just over 100k. There are opportunities to grow but employer is stingy with raise and career ladder is not clear after senior. However, work life balance is great - I am fully remote, rarely ever have to work over time and no micromanagement. Also no lay offs so far.</p>\n\n<p>I do often wonder if I could learn more from working for another company with big data and more modern tech stack. I am worried that the longer I stay here I might miss out on improving my technical skills and not be up to date with the job market. At the same time, I love having free time for my hobbies and having a low stress job...</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1faapqa', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Representative_Big47'), 'discussion_type': None, 'num_comments': 31, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faapqa/should_i_jump_ship/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faapqa/should_i_jump_ship/', 'subreddit_subscribers': 210878, 'created_utc': 1725613751.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.869+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hello! I\'m an EFL teacher who has recently started working with a data engineer, and I need to teach him how to talk about his job in English. The problem is, even though I\'ve learned the basic terms related to this area, I\'m not sure how to use them correctly in a sentence.\nFor example, pipelines. What do you do with them?  I\'ve seen the collocation "build pipelines", but I\'m sure there are much more.\n\nSo, what I\'m asking here is to help me find as many of these common collocations necessary to describe your job as possible. As if you were answering "What are your job responsibilities" question very thoroughly. \n\nThank you! ', 'author_fullname': 't2_dtfhc6ae', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'wtf you guys do', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fabhml', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.83, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 43, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 43, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725617112.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello! I&#39;m an EFL teacher who has recently started working with a data engineer, and I need to teach him how to talk about his job in English. The problem is, even though I&#39;ve learned the basic terms related to this area, I&#39;m not sure how to use them correctly in a sentence.\nFor example, pipelines. What do you do with them?  I&#39;ve seen the collocation &quot;build pipelines&quot;, but I&#39;m sure there are much more.</p>\n\n<p>So, what I&#39;m asking here is to help me find as many of these common collocations necessary to describe your job as possible. As if you were answering &quot;What are your job responsibilities&quot; question very thoroughly. </p>\n\n<p>Thank you! </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fabhml', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='eden_4004'), 'discussion_type': None, 'num_comments': 22, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fabhml/wtf_you_guys_do/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fabhml/wtf_you_guys_do/', 'subreddit_subscribers': 210878, 'created_utc': 1725617112.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.870+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I'm interested to see what people think of this idea. \n\nWith developments over the summer, it feels like Delta Lake and Apache Iceberg are truly converging into similar technologies. They've always been pretty similar in some ways, both data lakehouse table formats, but the similarities seem to have reached some kind of tipping point. You have Snowflake with Polaris, and Databricks with Unity. Both are open sourcing to the max, both are developing similar capabilities. In the case of Databricks, you even have Unity supporting both and their CEO saying that this will make the distinction between the two table formats almost meaningless in the end. Both offer many of the same features: time travel, schema evolution, ACID compliance, etc. \n\nSo what do people think? \n\nHave Iceberg and Delta Lake become almost the same thing? Obviously they work differently under the hood (manifest files vs Delta Log), but do their differences still mean something. Or have they just converged on one level, but are still different enough if you look underneath? I'm thinking maybe ecosystem integration. Delta is much more tightly integrated with Spark, for instance. \n\nThoughts?", 'author_fullname': 't2_p25cwdu4', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Are the differences between Delta Lake and Apache Iceberg fading away? ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faj4m2', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 31, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 31, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725639304.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;m interested to see what people think of this idea. </p>\n\n<p>With developments over the summer, it feels like Delta Lake and Apache Iceberg are truly converging into similar technologies. They&#39;ve always been pretty similar in some ways, both data lakehouse table formats, but the similarities seem to have reached some kind of tipping point. You have Snowflake with Polaris, and Databricks with Unity. Both are open sourcing to the max, both are developing similar capabilities. In the case of Databricks, you even have Unity supporting both and their CEO saying that this will make the distinction between the two table formats almost meaningless in the end. Both offer many of the same features: time travel, schema evolution, ACID compliance, etc. </p>\n\n<p>So what do people think? </p>\n\n<p>Have Iceberg and Delta Lake become almost the same thing? Obviously they work differently under the hood (manifest files vs Delta Log), but do their differences still mean something. Or have they just converged on one level, but are still different enough if you look underneath? I&#39;m thinking maybe ecosystem integration. Delta is much more tightly integrated with Spark, for instance. </p>\n\n<p>Thoughts?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1faj4m2', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Teach-To-The-Tech'), 'discussion_type': None, 'num_comments': 22, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faj4m2/are_the_differences_between_delta_lake_and_apache/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faj4m2/are_the_differences_between_delta_lake_and_apache/', 'subreddit_subscribers': 210878, 'created_utc': 1725639304.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.874+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Currently working as a data engineer for a smaller healthcare analytics company. I’ve been there for a little over 3 years. Before this role I worked in data warehouse development (primarily SQL, Snowflake and Azure). In my current role I work primarily with AWS and PySpark. I was stuck in the 80K range for several years, got a bump up to 100K about a year ago. How can I prepare for and land a role earning closer to $150K? At this point I think I have enough years of experience, but I probably lack the skill level with these tools to command that sort of salary. What should I study? Should I get any additional certifications? Currently only have Microsoft certs I earned several years ago (MCSE: Data Management and Analytics). I’m not in a rush, I love my company and have stability here, but even with promotions and salary bumps I know I won’t get anywhere near that in the next 2 years. Given inflation and my own personal financial goals, I’d really like to make a significant jump in income - especially because it seems like many others are doing it. Currently, I’m studying for the aws solution architect certification but I don’t really know what areas to focus on improving in python/pyspark, etc. Any advice appreciated!', 'author_fullname': 't2_q75ae8eb', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How to prepare to land a higher paying role ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1famd92', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.85, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 21, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 21, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725647496.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Currently working as a data engineer for a smaller healthcare analytics company. I’ve been there for a little over 3 years. Before this role I worked in data warehouse development (primarily SQL, Snowflake and Azure). In my current role I work primarily with AWS and PySpark. I was stuck in the 80K range for several years, got a bump up to 100K about a year ago. How can I prepare for and land a role earning closer to $150K? At this point I think I have enough years of experience, but I probably lack the skill level with these tools to command that sort of salary. What should I study? Should I get any additional certifications? Currently only have Microsoft certs I earned several years ago (MCSE: Data Management and Analytics). I’m not in a rush, I love my company and have stability here, but even with promotions and salary bumps I know I won’t get anywhere near that in the next 2 years. Given inflation and my own personal financial goals, I’d really like to make a significant jump in income - especially because it seems like many others are doing it. Currently, I’m studying for the aws solution architect certification but I don’t really know what areas to focus on improving in python/pyspark, etc. Any advice appreciated!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1famd92', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Intelligent_Today384'), 'discussion_type': None, 'num_comments': 12, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1famd92/how_to_prepare_to_land_a_higher_paying_role/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1famd92/how_to_prepare_to_land_a_higher_paying_role/', 'subreddit_subscribers': 210878, 'created_utc': 1725647496.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.875+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "\nIs it more beneficial in data engineering to become highly specialized in one or two key technologies, like mastering Spark, Azure, or is it better to have a broader knowledge across a wide range of tools and platforms? \n\nFor example, should I focus on becoming an expert in just a few technologies, or aim to be proficient in a wider range like Kafka, Airflow, SQL, and multiple cloud platforms? \n\nI'm curious which approach would be more valuable in the long run.", 'author_fullname': 't2_7z8db98wd', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Do you prefer being an expert in one technology or now a lot in general?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faf2xo', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 16, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 16, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725628996.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Is it more beneficial in data engineering to become highly specialized in one or two key technologies, like mastering Spark, Azure, or is it better to have a broader knowledge across a wide range of tools and platforms? </p>\n\n<p>For example, should I focus on becoming an expert in just a few technologies, or aim to be proficient in a wider range like Kafka, Airflow, SQL, and multiple cloud platforms? </p>\n\n<p>I&#39;m curious which approach would be more valuable in the long run.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1faf2xo', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Free-Traffic-3166'), 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faf2xo/do_you_prefer_being_an_expert_in_one_technology/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faf2xo/do_you_prefer_being_an_expert_in_one_technology/', 'subreddit_subscribers': 210878, 'created_utc': 1725628996.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.876+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hello there! I'm looking for good platforms or other places to search for a job.\n\n**Background**.\n\n`I live in Eastern Europe. I've been in software development for 3-4 years now. I learned Python by myself and worked full-time as an independent contractor at a US company as a Data Engineer for 2 recent years completely remote.`\n\n`I never worked in the local IT industry market because we have a lot of outsourced IT companies who have insane requirements, selling you for $50 per hour and offering you $10-15 in return. That is not accurate rates, just an example to explain the overall situation.`\n\n`That was really fun for me when for the first year of my journey in Python local companies were denying me because of my poor knowledge and lack of commerce experience for junior positions with a $500 per month salary. And at the same time, people were hiring me to create scripts and scrapers for $100 and more which required 1-3 days of noob job at that time. There was a point when a dude hired me for $2k per month for a couple of months to write scrapers.`\n\n`I focused on UpWork at that time and my clients were from there, some randomly found me on LinkedIn by themselves. Also, I had a YouTube channel with 3 videos and some people found me there. I worked all the time with people from North America and Europe.`\n\nIn two recent years, I worked with the same employer that reached me on Upwork.\n\n**Upwork** has changed in those years and now it consumes Connects (tokens to send job applications) like hell. You can spend $10-20 per day for nothing or even more, there is no limit to that craziness.\n\n**LinkedIn** is a very random source because nobody can contact you for months but on other days 5 persons in a row could text you.\n\nI tried **Fiverr** but its system with ads is weird and more suitable for art creators rather than software devs. Nobody ever contacted me from there.\n\nTried **Freelancercom** which is more like Upwork and more loyal to investment to find something but I didn't succeed there.\n\n**Toptal** denied me for now but they are very demanding and I'm not a Super-Giga-Pro-Senior-Architect so that is okay for now.\n\n>Could it be valuable to use traditional platforms like Indeed in the US, CA, UK, IR etc (North America and Europe) domains to catch a full-time or at least part-time contract? Or do people search there only for locals?\n\nFor example, I know that in the US W2 and 401k marking means that the job is for locals but I know that there are independent contracts and that is how I worked in previous years with that long-term job I described earlier. That just came randomly from Upwork.\n\nI don't want to uselessly spam recruiters so my questions are:\n\n1. Is it possible to find contract opportunities for remote foreign contractors like me on conventional job boards? How those job posts might be marked? I'm a single freelancer and I can't relocate from my country for now, unfortunately, just in case.\n2. Any advice about any platform or job board that I could try is welcome.\n3. Are there any specific job boards for IT specialists that are welcoming for foreign freelancers like me in the US, UK, CA, IR and EU overall?\n\n`I mentioned the US, UK, CA, IR and EU several times because those are countries where I had clients in the past and didn't have any trouble working or communicating with them. So will be glad in advice that is relevant to any of them.`\n\nThanks to everyone who will find time to share their thoughts.", 'author_fullname': 't2_j2gri1ul', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Good places to search for a remote job', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faj8zu', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.94, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 13, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 13, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1725641825.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725639609.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello there! I&#39;m looking for good platforms or other places to search for a job.</p>\n\n<p><strong>Background</strong>.</p>\n\n<p><code>I live in Eastern Europe. I&#39;ve been in software development for 3-4 years now. I learned Python by myself and worked full-time as an independent contractor at a US company as a Data Engineer for 2 recent years completely remote.</code></p>\n\n<p><code>I never worked in the local IT industry market because we have a lot of outsourced IT companies who have insane requirements, selling you for $50 per hour and offering you $10-15 in return. That is not accurate rates, just an example to explain the overall situation.</code></p>\n\n<p><code>That was really fun for me when for the first year of my journey in Python local companies were denying me because of my poor knowledge and lack of commerce experience for junior positions with a $500 per month salary. And at the same time, people were hiring me to create scripts and scrapers for $100 and more which required 1-3 days of noob job at that time. There was a point when a dude hired me for $2k per month for a couple of months to write scrapers.</code></p>\n\n<p><code>I focused on UpWork at that time and my clients were from there, some randomly found me on LinkedIn by themselves. Also, I had a YouTube channel with 3 videos and some people found me there. I worked all the time with people from North America and Europe.</code></p>\n\n<p>In two recent years, I worked with the same employer that reached me on Upwork.</p>\n\n<p><strong>Upwork</strong> has changed in those years and now it consumes Connects (tokens to send job applications) like hell. You can spend $10-20 per day for nothing or even more, there is no limit to that craziness.</p>\n\n<p><strong>LinkedIn</strong> is a very random source because nobody can contact you for months but on other days 5 persons in a row could text you.</p>\n\n<p>I tried <strong>Fiverr</strong> but its system with ads is weird and more suitable for art creators rather than software devs. Nobody ever contacted me from there.</p>\n\n<p>Tried <strong>Freelancercom</strong> which is more like Upwork and more loyal to investment to find something but I didn&#39;t succeed there.</p>\n\n<p><strong>Toptal</strong> denied me for now but they are very demanding and I&#39;m not a Super-Giga-Pro-Senior-Architect so that is okay for now.</p>\n\n<blockquote>\n<p>Could it be valuable to use traditional platforms like Indeed in the US, CA, UK, IR etc (North America and Europe) domains to catch a full-time or at least part-time contract? Or do people search there only for locals?</p>\n</blockquote>\n\n<p>For example, I know that in the US W2 and 401k marking means that the job is for locals but I know that there are independent contracts and that is how I worked in previous years with that long-term job I described earlier. That just came randomly from Upwork.</p>\n\n<p>I don&#39;t want to uselessly spam recruiters so my questions are:</p>\n\n<ol>\n<li>Is it possible to find contract opportunities for remote foreign contractors like me on conventional job boards? How those job posts might be marked? I&#39;m a single freelancer and I can&#39;t relocate from my country for now, unfortunately, just in case.</li>\n<li>Any advice about any platform or job board that I could try is welcome.</li>\n<li>Are there any specific job boards for IT specialists that are welcoming for foreign freelancers like me in the US, UK, CA, IR and EU overall?</li>\n</ol>\n\n<p><code>I mentioned the US, UK, CA, IR and EU several times because those are countries where I had clients in the past and didn&#39;t have any trouble working or communicating with them. So will be glad in advice that is relevant to any of them.</code></p>\n\n<p>Thanks to everyone who will find time to share their thoughts.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1faj8zu', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='bezel_zelek'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faj8zu/good_places_to_search_for_a_remote_job/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faj8zu/good_places_to_search_for_a_remote_job/', 'subreddit_subscribers': 210878, 'created_utc': 1725639609.0, 'num_crossposts': 1, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.877+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi, I have very little knowledge of software engineering but have been working my way by learning from reddit/stack-overflow and experimentation. I would like to learn about cheap ways I could make about 10 TB of data available to my users.\n\nAs of now, I have about 1TB of data stored in my external SSD. I have attached this SSD to my wifi router and have configured NAT to make it available over the internet. It is an FTP server and I have a python wrapper that facilitates the read/write operations. This costs me about $50 per month for internet connection and a one time cost for the SSD.\n\nFor the sake of simplicity, lets assume with 10TB of data:\n\n* Each file size is \\~100 Mb\n* 60000 reads per day\n* 10000 writes per day\n* data is partitioned by group\\_1/sub\\_group\\_1/sub\\_sub\\_group\\_1/year/month/day\n\nI went through pricing documentation of AWS S3, and it seems it would cost me well over $1000 per month.\n\nI am tempted to buy more SSDs and configure them with my router. I believe with increasing requests the router with clog up and give rise to increased latency issues. I was wondering if I can get more than 1 internet connection. This way the cost of external SSDs are a 1-time cost, internet connection cost is much lower than AWS s3 and read/write is free.\n\nAm I going in a completely wrong direction?? What are other alternate low-cost, low-latency options?\n\nAny help/feedback direction is appreciated.\n\nThanks!  \n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\nEDIT:  \nI am building a platform that allows users to apply custom filters to a given song.\n\n- Applying a filter to a song is a slow-ish operation.  \n- I want my users to be able to apply any number of filters to a song.  \n- I want to pre-compute weights for different filters so it can be applied to a song in one go', 'author_fullname': 't2_s14qn2lhq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How to make 10TB of data available on-demand to my users', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faj1q1', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.88, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 11, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 11, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1725667545.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725639106.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi, I have very little knowledge of software engineering but have been working my way by learning from reddit/stack-overflow and experimentation. I would like to learn about cheap ways I could make about 10 TB of data available to my users.</p>\n\n<p>As of now, I have about 1TB of data stored in my external SSD. I have attached this SSD to my wifi router and have configured NAT to make it available over the internet. It is an FTP server and I have a python wrapper that facilitates the read/write operations. This costs me about $50 per month for internet connection and a one time cost for the SSD.</p>\n\n<p>For the sake of simplicity, lets assume with 10TB of data:</p>\n\n<ul>\n<li>Each file size is ~100 Mb</li>\n<li>60000 reads per day</li>\n<li>10000 writes per day</li>\n<li>data is partitioned by group_1/sub_group_1/sub_sub_group_1/year/month/day</li>\n</ul>\n\n<p>I went through pricing documentation of AWS S3, and it seems it would cost me well over $1000 per month.</p>\n\n<p>I am tempted to buy more SSDs and configure them with my router. I believe with increasing requests the router with clog up and give rise to increased latency issues. I was wondering if I can get more than 1 internet connection. This way the cost of external SSDs are a 1-time cost, internet connection cost is much lower than AWS s3 and read/write is free.</p>\n\n<p>Am I going in a completely wrong direction?? What are other alternate low-cost, low-latency options?</p>\n\n<p>Any help/feedback direction is appreciated.</p>\n\n<p>Thanks!<br/>\n____________________________________________________________________________________</p>\n\n<p>EDIT:<br/>\nI am building a platform that allows users to apply custom filters to a given song.</p>\n\n<ul>\n<li>Applying a filter to a song is a slow-ish operation.<br/></li>\n<li>I want my users to be able to apply any number of filters to a song.<br/></li>\n<li>I want to pre-compute weights for different filters so it can be applied to a song in one go</li>\n</ul>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1faj1q1', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='explorer_soul99'), 'discussion_type': None, 'num_comments': 10, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faj1q1/how_to_make_10tb_of_data_available_ondemand_to_my/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faj1q1/how_to_make_10tb_of_data_available_ondemand_to_my/', 'subreddit_subscribers': 210878, 'created_utc': 1725639106.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.877+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '\nAfter months of confusion on where i want be a data scientist or a data engineer. Finally I realized I’m interested in Data engineering. I’m setting my foot into Data engineering with a clear head and want to start building projects. \n\nWhich one would you suggest getting Hands-on with? AWS or Azure? Or what else would you suggest, that might be helpful for my job hunt in this market??', 'author_fullname': 't2_138q0rrqxt', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Azure vs Aws', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fatayj', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 9, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 9, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725665639.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>After months of confusion on where i want be a data scientist or a data engineer. Finally I realized I’m interested in Data engineering. I’m setting my foot into Data engineering with a clear head and want to start building projects. </p>\n\n<p>Which one would you suggest getting Hands-on with? AWS or Azure? Or what else would you suggest, that might be helpful for my job hunt in this market??</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1fatayj', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Then_Sundae_7645'), 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fatayj/azure_vs_aws/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fatayj/azure_vs_aws/', 'subreddit_subscribers': 210878, 'created_utc': 1725665639.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.878+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'For example, let\'s say you\'re getting data from Crunchbase, Pitchbook, and LinkedIn. How do you "standardize" across these different data providers? \n\n  \nI\'m working on a mapping algorithm for building crosswalks between data sources. Curious to know if anyone deals with these issues and if you have an out of the box solution you use. ', 'author_fullname': 't2_cqdfu7nf4', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How are you standardizing data across different external sources?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faqljq', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 8, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 8, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725658238.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>For example, let&#39;s say you&#39;re getting data from Crunchbase, Pitchbook, and LinkedIn. How do you &quot;standardize&quot; across these different data providers? </p>\n\n<p>I&#39;m working on a mapping algorithm for building crosswalks between data sources. Curious to know if anyone deals with these issues and if you have an out of the box solution you use. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1faqljq', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Different-General700'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faqljq/how_are_you_standardizing_data_across_different/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faqljq/how_are_you_standardizing_data_across_different/', 'subreddit_subscribers': 210878, 'created_utc': 1725658238.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.879+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '1) I am trying to see if the VENV should be within the project folder? \n\n2) or if I should have a separate directory with all my VENVs?\n\nIf its 1), does that mean I need to remember to add it to my gitignore file? ', 'author_fullname': 't2_11isd4n423', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Where do you create your python virtual environments in your local dev env?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1famvc9', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725648799.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>1) I am trying to see if the VENV should be within the project folder? </p>\n\n<p>2) or if I should have a separate directory with all my VENVs?</p>\n\n<p>If its 1), does that mean I need to remember to add it to my gitignore file? </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1famvc9', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Green-Aide-2354'), 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1famvc9/where_do_you_create_your_python_virtual/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1famvc9/where_do_you_create_your_python_virtual/', 'subreddit_subscribers': 210878, 'created_utc': 1725648799.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.880+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I use AWS S3, DynamoDB, Lambda, Cloudwatch and Redshift at my job but I don’t use these things everyday and honestly just have interacted with these tools so far without really know what im doing. I saw AWS has a skill builder course and see both an actual course and cloud quest game. Are these enough to get started with the basics? I’m not planning to get certification just yet, just a higher level and technical overview would be good ', 'author_fullname': 't2_2prckadt', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Best resources to learn AWS', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fal8p2', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.88, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725644642.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I use AWS S3, DynamoDB, Lambda, Cloudwatch and Redshift at my job but I don’t use these things everyday and honestly just have interacted with these tools so far without really know what im doing. I saw AWS has a skill builder course and see both an actual course and cloud quest game. Are these enough to get started with the basics? I’m not planning to get certification just yet, just a higher level and technical overview would be good </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1fal8p2', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='thro0away12'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fal8p2/best_resources_to_learn_aws/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fal8p2/best_resources_to_learn_aws/', 'subreddit_subscribers': 210878, 'created_utc': 1725644642.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.882+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I have recently started working with pyspark and need advice on how to optimize spark job performance when processing large amounts of data .\n\nWhat would be some ways to improve performance for data transformations when working with spark dataframes?\n\nAny tips would be greatly appreciated , thanks!', 'author_fullname': 't2_ipbf10dq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Apache Spark(Pyspark) Performance tuning tips and tricks', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fafxy6', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.78, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725631308.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I have recently started working with pyspark and need advice on how to optimize spark job performance when processing large amounts of data .</p>\n\n<p>What would be some ways to improve performance for data transformations when working with spark dataframes?</p>\n\n<p>Any tips would be greatly appreciated , thanks!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fafxy6', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Notalabel_4566'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fafxy6/apache_sparkpyspark_performance_tuning_tips_and/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fafxy6/apache_sparkpyspark_performance_tuning_tips_and/', 'subreddit_subscribers': 210878, 'created_utc': 1725631308.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.883+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I went to try to set this up in my new Cursor(VS Code) environment and it looks like its been erased from existence.  Github appears to be gone.  Search results are all 1+ years old.  Did this get pulled and I just missed it?  I've been using this every day for some time now.", 'author_fullname': 't2_d2j8u', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What happened to "Wizard for dbt Core" and the Fivetran dbt language server?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fagxhg', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.63, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725633865.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I went to try to set this up in my new Cursor(VS Code) environment and it looks like its been erased from existence.  Github appears to be gone.  Search results are all 1+ years old.  Did this get pulled and I just missed it?  I&#39;ve been using this every day for some time now.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1fagxhg', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='warpraptor'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fagxhg/what_happened_to_wizard_for_dbt_core_and_the/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fagxhg/what_happened_to_wizard_for_dbt_core_and_the/', 'subreddit_subscribers': 210878, 'created_utc': 1725633865.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.884+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I think many of us have imagined to run unit tests or e2e test against the "data" (not the code that generates the data) to check if the data meet some criteria and then "release the data" to maintain data reliability. here is how I approach it:\n\n[https://medium.com/@matao.xjtu/database-release-and-end-to-end-testing-juicefs-bring-modern-software-development-best-practice-ee7e5115a668](https://medium.com/@matao.xjtu/database-release-and-end-to-end-testing-juicefs-bring-modern-software-development-best-practice-ee7e5115a668)', 'author_fullname': 't2_jlzg0j3w', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'End-to-End Testing and Release in Data World', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fafk2l', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725630281.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I think many of us have imagined to run unit tests or e2e test against the &quot;data&quot; (not the code that generates the data) to check if the data meet some criteria and then &quot;release the data&quot; to maintain data reliability. here is how I approach it:</p>\n\n<p><a href="https://medium.com/@matao.xjtu/database-release-and-end-to-end-testing-juicefs-bring-modern-software-development-best-practice-ee7e5115a668">https://medium.com/@matao.xjtu/database-release-and-end-to-end-testing-juicefs-bring-modern-software-development-best-practice-ee7e5115a668</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/Mpwh5mLjCpQ12KYADgBJgym7PZAaB8pCS0d4NxyyU90.jpg?auto=webp&s=58c0115ee3590b38ffbda2b56f93bf6b43c9a4ad', 'width': 1200, 'height': 1072}, 'resolutions': [{'url': 'https://external-preview.redd.it/Mpwh5mLjCpQ12KYADgBJgym7PZAaB8pCS0d4NxyyU90.jpg?width=108&crop=smart&auto=webp&s=f3e195ea0ef91b77e03540440ada291fd95a939c', 'width': 108, 'height': 96}, {'url': 'https://external-preview.redd.it/Mpwh5mLjCpQ12KYADgBJgym7PZAaB8pCS0d4NxyyU90.jpg?width=216&crop=smart&auto=webp&s=4518d4292a99facdbce2067512c47cc0550c3454', 'width': 216, 'height': 192}, {'url': 'https://external-preview.redd.it/Mpwh5mLjCpQ12KYADgBJgym7PZAaB8pCS0d4NxyyU90.jpg?width=320&crop=smart&auto=webp&s=d83941a58153016df898b4e849365df8cf402115', 'width': 320, 'height': 285}, {'url': 'https://external-preview.redd.it/Mpwh5mLjCpQ12KYADgBJgym7PZAaB8pCS0d4NxyyU90.jpg?width=640&crop=smart&auto=webp&s=32f6e139f83d81df33ede27998e0cb9c895442b4', 'width': 640, 'height': 571}, {'url': 'https://external-preview.redd.it/Mpwh5mLjCpQ12KYADgBJgym7PZAaB8pCS0d4NxyyU90.jpg?width=960&crop=smart&auto=webp&s=d0644609062eda1488f5c60614ceef50e83408bb', 'width': 960, 'height': 857}, {'url': 'https://external-preview.redd.it/Mpwh5mLjCpQ12KYADgBJgym7PZAaB8pCS0d4NxyyU90.jpg?width=1080&crop=smart&auto=webp&s=9e9b3911edba103fc526ba1d40eef788b65f66e5', 'width': 1080, 'height': 964}], 'variants': {}, 'id': 'ANOpVV0d_mpwcGYIaBqd_PAZAdC3hdiq9bdEmZwiZqc'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1fafk2l', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Senior_Kiwi_4628'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fafk2l/endtoend_testing_and_release_in_data_world/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fafk2l/endtoend_testing_and_release_in_data_world/', 'subreddit_subscribers': 210878, 'created_utc': 1725630281.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.885+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi everyone,\n\nI would like to read data from Mongo on a daily basis, do some transformations on Python, and save them into PostgreSQL. Since I am doing it a constant time interval, first, I thought to accomplish the job by checking update dates, but MongoDB collections is not configured to store update dates. So, I would like to use something that handles the job of bookmarking already processed data, so I do not process the same document over and over again.\n\nWhat do you suggest? Any tool, method, etc...', 'author_fullname': 't2_t1xjvr55', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Stateful Data Transfer from Mongo to PostgreSQL', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faeesq', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725627109.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi everyone,</p>\n\n<p>I would like to read data from Mongo on a daily basis, do some transformations on Python, and save them into PostgreSQL. Since I am doing it a constant time interval, first, I thought to accomplish the job by checking update dates, but MongoDB collections is not configured to store update dates. So, I would like to use something that handles the job of bookmarking already processed data, so I do not process the same document over and over again.</p>\n\n<p>What do you suggest? Any tool, method, etc...</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1faeesq', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='gxslash'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faeesq/stateful_data_transfer_from_mongo_to_***ql/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faeesq/stateful_data_transfer_from_mongo_to_***ql/', 'subreddit_subscribers': 210878, 'created_utc': 1725627109.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.886+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I'm currently doing some research into full text search methods in order to build my own search engine. Right now I have managed to get a pretty fast prefix search using a form of trie, but ideally the engine should be able to do infix search similar to\xa0`like '%foo%'`\xa0in SQL. I know that Typesense uses a HAT trie for this, but I could not figure out how they use it exactly. Another way I found was to use suffix arrays or suffix tries, but they seem very memory inefficient as they store every possible suffix. For context, the data being indexed will have rows somewhere in the 6 digit range, with each having about 0.5kB of data. My questions are:\n\n* Is this even realistically achievable?\n* How can a HAT trie be used for this, as typesense does?\n* How do the built-in full-text indexes in SQL work?\n* What would you recommend as a suitable approach?\n\nI am not able to use any of the built-in features of a DBMS, so the engine will have to run completely on its own. Thank you for your helpThank you for your help", 'author_fullname': 't2_7u4n9tzm', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Data structures for Full-Text-Indexing', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1farhb0', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725660586.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;m currently doing some research into full text search methods in order to build my own search engine. Right now I have managed to get a pretty fast prefix search using a form of trie, but ideally the engine should be able to do infix search similar to\xa0<code>like &#39;%foo%&#39;</code>\xa0in SQL. I know that Typesense uses a HAT trie for this, but I could not figure out how they use it exactly. Another way I found was to use suffix arrays or suffix tries, but they seem very memory inefficient as they store every possible suffix. For context, the data being indexed will have rows somewhere in the 6 digit range, with each having about 0.5kB of data. My questions are:</p>\n\n<ul>\n<li>Is this even realistically achievable?</li>\n<li>How can a HAT trie be used for this, as typesense does?</li>\n<li>How do the built-in full-text indexes in SQL work?</li>\n<li>What would you recommend as a suitable approach?</li>\n</ul>\n\n<p>I am not able to use any of the built-in features of a DBMS, so the engine will have to run completely on its own. Thank you for your helpThank you for your help</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1farhb0', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='International-Tap906'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1farhb0/data_structures_for_fulltextindexing/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1farhb0/data_structures_for_fulltextindexing/', 'subreddit_subscribers': 210878, 'created_utc': 1725660586.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.887+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hello, I'm fresh from university and currently doing some side projects in order to land a job in *data* position - preferably Data Analyst. Nevertheless, I've decided to do also a bit of data engineering and since I'm a beginner in this field, I'm seeking some advice.\n\nI have access to the database of my friends' e-commerce web platform and my idea was to create him a data pipeline. His database is not big - 400MB, and creates around few thousand transactions each year. Nevertheless, I thought of creating an ETL (or ELT with dbt) process that would read the data from the OLTP database of the web platform and store it in the Data Warehouse (star schema) in snowflake using dbt. Afterwards, I would connect Tableau to the Data Warehouse.\n\nThe result be would near real time analytics through Tableau.\n\nQuestions:\n\n* Are these technologies (snowflake and dbt) suitable for the work planned, if not what are?\n* Also, I'm aware the technologies are a bit overkill for the task (since the database is small), but the intend here is to do it by industry standards for the CV.\n* Do you have any (technical) resources that explain the process as I've explained?\n\nThanks in advance!", 'author_fullname': 't2_avs8y0wo', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Need advice for creating Data pipeline', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faqn28', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725658349.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello, I&#39;m fresh from university and currently doing some side projects in order to land a job in <em>data</em> position - preferably Data Analyst. Nevertheless, I&#39;ve decided to do also a bit of data engineering and since I&#39;m a beginner in this field, I&#39;m seeking some advice.</p>\n\n<p>I have access to the database of my friends&#39; e-commerce web platform and my idea was to create him a data pipeline. His database is not big - 400MB, and creates around few thousand transactions each year. Nevertheless, I thought of creating an ETL (or ELT with dbt) process that would read the data from the OLTP database of the web platform and store it in the Data Warehouse (star schema) in snowflake using dbt. Afterwards, I would connect Tableau to the Data Warehouse.</p>\n\n<p>The result be would near real time analytics through Tableau.</p>\n\n<p>Questions:</p>\n\n<ul>\n<li>Are these technologies (snowflake and dbt) suitable for the work planned, if not what are?</li>\n<li>Also, I&#39;m aware the technologies are a bit overkill for the task (since the database is small), but the intend here is to do it by industry standards for the CV.</li>\n<li>Do you have any (technical) resources that explain the process as I&#39;ve explained?</li>\n</ul>\n\n<p>Thanks in advance!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1faqn28', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Nochioni'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faqn28/need_advice_for_creating_data_pipeline/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faqn28/need_advice_for_creating_data_pipeline/', 'subreddit_subscribers': 210878, 'created_utc': 1725658349.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.888+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Can somebody suggest good content that covers system design for senior data engineering leadership roles . I am mainly targeting leadership roles for data engineering ?', 'author_fullname': 't2_7n9bwo7p', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Senior Roles - Data Engineering ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fahrgw', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725635921.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Can somebody suggest good content that covers system design for senior data engineering leadership roles . I am mainly targeting leadership roles for data engineering ?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1fahrgw', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Hungry_Resolution421'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fahrgw/senior_roles_data_engineering/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fahrgw/senior_roles_data_engineering/', 'subreddit_subscribers': 210878, 'created_utc': 1725635921.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.889+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'My company is looking for a new ETL process but wants to keep the existing EDW on prem SQL server. What are some solutions where we can pull data from db2, do ETL using cloud compute, and then bring it to our sql server. I thought of using an orchestration tool like airflow or dragster. Spinning up compute containers using docker. And using python/sql to script. But they also want a managed solution and something with support. Thoughts?\n\nFYI: we are moving away from informatica and I would prefer if we don’t go with another outdated GUI tool.', 'author_fullname': 't2_d9d6chv71', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Cloud compute for on prem DW', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fah1v8', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725634167.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>My company is looking for a new ETL process but wants to keep the existing EDW on prem SQL server. What are some solutions where we can pull data from db2, do ETL using cloud compute, and then bring it to our sql server. I thought of using an orchestration tool like airflow or dragster. Spinning up compute containers using docker. And using python/sql to script. But they also want a managed solution and something with support. Thoughts?</p>\n\n<p>FYI: we are moving away from informatica and I would prefer if we don’t go with another outdated GUI tool.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fah1v8', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='putt_stuff98'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fah1v8/cloud_compute_for_on_prem_dw/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fah1v8/cloud_compute_for_on_prem_dw/', 'subreddit_subscribers': 210878, 'created_utc': 1725634167.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.889+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I’m from the UK and I’ve been having the urge to want to move abroad in the future  in particular the middle east- Qatar, Dubai mainly and to work there in data(analytics/science/engineering) \nand just have been looking at some jobs there and seen most if not all require you to have a degree. Does anyone know if it’s possible to get a job there  without a degree and just mainly on few years experience? ', 'author_fullname': 't2_bnt0f0qx', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Degree to work abroad ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faajzd', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725613037.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I’m from the UK and I’ve been having the urge to want to move abroad in the future  in particular the middle east- Qatar, Dubai mainly and to work there in data(analytics/science/engineering) \nand just have been looking at some jobs there and seen most if not all require you to have a degree. Does anyone know if it’s possible to get a job there  without a degree and just mainly on few years experience? </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1faajzd', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Proper_Jackfruit_185'), 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faajzd/degree_to_work_abroad/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faajzd/degree_to_work_abroad/', 'subreddit_subscribers': 210878, 'created_utc': 1725613037.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.890+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hello DE experts.\n\nI was curious to know if anyone knew how to implement automated model selection within Snowpark? SF folks have been advocating to our ML teams to use Snowpark and we have already have a  very good Spark-based pipeline running in EMR and step functions that costs us very little that selects the best model/ML algorithm based on a variety of scores, but we couldn't see a cost-effective way of doing this in Snowpark aside from running multiple large warehouses simultaneously, or something similar to that.\n\nThanks!", 'author_fullname': 't2_vnf5zckf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Snowpark question around model selection', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fau4fj', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725668007.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello DE experts.</p>\n\n<p>I was curious to know if anyone knew how to implement automated model selection within Snowpark? SF folks have been advocating to our ML teams to use Snowpark and we have already have a  very good Spark-based pipeline running in EMR and step functions that costs us very little that selects the best model/ML algorithm based on a variety of scores, but we couldn&#39;t see a cost-effective way of doing this in Snowpark aside from running multiple large warehouses simultaneously, or something similar to that.</p>\n\n<p>Thanks!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1fau4fj', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Separate-Purple5671'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fau4fj/snowpark_question_around_model_selection/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fau4fj/snowpark_question_around_model_selection/', 'subreddit_subscribers': 210878, 'created_utc': 1725668007.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.890+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi! I would love to know your thoughts on [this ](https://www.udemy.com/course/aws-data-engineer/)course for a novice DE transitioning from software engineering (regardless of the importance of the exam)', 'author_fullname': 't2_koehjpk6', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Thoughts on this course for a beginner DE', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1famd7w', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.6, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725647494.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi! I would love to know your thoughts on <a href="https://www.udemy.com/course/aws-data-engineer/">this </a>course for a novice DE transitioning from software engineering (regardless of the importance of the exam)</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1famd7w', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='FinanceOld3216'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1famd7w/thoughts_on_this_course_for_a_beginner_de/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1famd7w/thoughts_on_this_course_for_a_beginner_de/', 'subreddit_subscribers': 210878, 'created_utc': 1725647494.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.891+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I'm currently trying to integrate segment with Snowflake as destination. I am trying to understand if moving data from Segment to Snowflake will cost me a lot of Snowflake credits since data would come in very frequently.", 'author_fullname': 't2_afnzbvoc', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Using Segment with Snowflake', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faejre', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1725628569.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725627520.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;m currently trying to integrate segment with Snowflake as destination. I am trying to understand if moving data from Segment to Snowflake will cost me a lot of Snowflake credits since data would come in very frequently.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1faejre', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Mediocre-Cow354'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faejre/using_segment_with_snowflake/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faejre/using_segment_with_snowflake/', 'subreddit_subscribers': 210878, 'created_utc': 1725627520.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.892+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Anyone able to send me an installer for Atanasuite? The websites no longer available. Thanks.\n\nEDIT: I have a license.', 'author_fullname': 't2_gq4p4dlwr', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Atanasuite (Teradata Client) download', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fad86s', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725623501.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Anyone able to send me an installer for Atanasuite? The websites no longer available. Thanks.</p>\n\n<p>EDIT: I have a license.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fad86s', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Optus_SimCard'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fad86s/atanasuite_teradata_client_download/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fad86s/atanasuite_teradata_client_download/', 'subreddit_subscribers': 210878, 'created_utc': 1725623501.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.892+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I'm currently working on a project that is fully implemented in Python. The workflow involves retrieving data from a third-party API, then utilizing AI services to extract additional information from this data. Both of these initial stages produce data in JSON format. From there, the JSON data is converted into a tabular format (CSV) for further processing.\n\nThe project has three more stages:\n\n1. Data transformation (filtering, removing duplicates, etc.).\n2. Clustering.\n3. Reusing AI services for extracting additional information.\n\nThese stages currently use CSV files as both input and output. Finally, the processed data is pushed to a relational database in Azure.\n\nThe original design was structured this way because the team who set it up were not technical. They wanted to manually validate the data between stages by opening the CSVs in Excel to ensure everything looked correct before moving to the next step.\n\nAs you can imagine, this has resulted in a somewhat messy data pipeline. I'm looking for advice on the best way to handle data between these stages. Should we keep the data in JSON format (in memory) until it's ready to be pushed to the database, or should we store it in a relational database after each stage and then query it for the next stage?\n\nI’m fairly new to this, so I would greatly appreciate any guidance. Thank you!", 'author_fullname': 't2_aek4m4bd', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Advice needed: Optimizing data flow for complex Python project', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faahyz', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725612787.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;m currently working on a project that is fully implemented in Python. The workflow involves retrieving data from a third-party API, then utilizing AI services to extract additional information from this data. Both of these initial stages produce data in JSON format. From there, the JSON data is converted into a tabular format (CSV) for further processing.</p>\n\n<p>The project has three more stages:</p>\n\n<ol>\n<li>Data transformation (filtering, removing duplicates, etc.).</li>\n<li>Clustering.</li>\n<li>Reusing AI services for extracting additional information.</li>\n</ol>\n\n<p>These stages currently use CSV files as both input and output. Finally, the processed data is pushed to a relational database in Azure.</p>\n\n<p>The original design was structured this way because the team who set it up were not technical. They wanted to manually validate the data between stages by opening the CSVs in Excel to ensure everything looked correct before moving to the next step.</p>\n\n<p>As you can imagine, this has resulted in a somewhat messy data pipeline. I&#39;m looking for advice on the best way to handle data between these stages. Should we keep the data in JSON format (in memory) until it&#39;s ready to be pushed to the database, or should we store it in a relational database after each stage and then query it for the next stage?</p>\n\n<p>I’m fairly new to this, so I would greatly appreciate any guidance. Thank you!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1faahyz', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Traditional_Cod_9001'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faahyz/advice_needed_optimizing_data_flow_for_complex/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faahyz/advice_needed_optimizing_data_flow_for_complex/', 'subreddit_subscribers': 210878, 'created_utc': 1725612787.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.893+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi All,\n\nI have almost 5 years of work experience as oracle DB developer and just started as data engineer few months ago. So I have really good sql knowledge. In my new project we use Azure synapse analytics and I want to do azure data engineer certification. Any guidance on the certification preparation is much appreciated. I found a udemy course but not sure if it is enough as I am a complete beginner in Data engineering and python. So any advice on courses or YouTube tutorials will be of great help. Thanks ', 'author_fullname': 't2_9h8njmrlt', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Azure Data engineer certification help', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fa9sxm', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.6, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725609650.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi All,</p>\n\n<p>I have almost 5 years of work experience as oracle DB developer and just started as data engineer few months ago. So I have really good sql knowledge. In my new project we use Azure synapse analytics and I want to do azure data engineer certification. Any guidance on the certification preparation is much appreciated. I found a udemy course but not sure if it is enough as I am a complete beginner in Data engineering and python. So any advice on courses or YouTube tutorials will be of great help. Thanks </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1fa9sxm', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Evening_Mouse_9582'), 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fa9sxm/azure_data_engineer_certification_help/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fa9sxm/azure_data_engineer_certification_help/', 'subreddit_subscribers': 210878, 'created_utc': 1725609650.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.893+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "That's it. Let's see what your setup looks like.\n\nGive us some highlights. Brag a bit.\n\nHere's mine: [https://github.com/ivanovyordan/dotfiles](https://github.com/ivanovyordan/dotfiles)\n\n*  I keep all my config in a single directory and link them using a tool called Stow.\n* Also, instead of a POSIX-compliant shell like Bash or Zsh, I use Fish.\n* My editor of choice is Neovim. Never managed to convert to VS Code.", 'author_fullname': 't2_1c6f704', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Share your dotfiles', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faffxt', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.5, 'author_flair_background_color': 'transparent', 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': '9ecf3c88-e787-11ed-957e-de1616aeae13', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725629979.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>That&#39;s it. Let&#39;s see what your setup looks like.</p>\n\n<p>Give us some highlights. Brag a bit.</p>\n\n<p>Here&#39;s mine: <a href="https://github.com/ivanovyordan/dotfiles">https://github.com/ivanovyordan/dotfiles</a></p>\n\n<ul>\n<li> I keep all my config in a single directory and link them using a tool called Stow.</li>\n<li>Also, instead of a POSIX-compliant shell like Bash or Zsh, I use Fish.</li>\n<li>My editor of choice is Neovim. Never managed to convert to VS Code.</li>\n</ul>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/JoUtQrBjYbLktWEo4JhgvTVVt55c06BLY76XYPqwcFc.jpg?auto=webp&s=7c3a0e555f0751d1e7305f1cf04429899e1cec52', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/JoUtQrBjYbLktWEo4JhgvTVVt55c06BLY76XYPqwcFc.jpg?width=108&crop=smart&auto=webp&s=86edbcc94fafc7944f01a8521378419e7718d1fc', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/JoUtQrBjYbLktWEo4JhgvTVVt55c06BLY76XYPqwcFc.jpg?width=216&crop=smart&auto=webp&s=0497e563141ae73bea6f1633269ef5c23f326e36', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/JoUtQrBjYbLktWEo4JhgvTVVt55c06BLY76XYPqwcFc.jpg?width=320&crop=smart&auto=webp&s=502bc05b0daae22fec5222c6bb8eb4ea72554955', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/JoUtQrBjYbLktWEo4JhgvTVVt55c06BLY76XYPqwcFc.jpg?width=640&crop=smart&auto=webp&s=688e4855d64201a9ae0d903cf76648539076f05f', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/JoUtQrBjYbLktWEo4JhgvTVVt55c06BLY76XYPqwcFc.jpg?width=960&crop=smart&auto=webp&s=156dbf36c0e182d5d6e66f2273597acb9956771f', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/JoUtQrBjYbLktWEo4JhgvTVVt55c06BLY76XYPqwcFc.jpg?width=1080&crop=smart&auto=webp&s=51c79f8c8bf5c9c0b55387a3b2d2aae4f00e3d14', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'Y7txmNNjmtqK8aJuaE0DAfT20HDFGcjeRpJYq6opn2w'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Data Engineering Manager', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1faffxt', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='ivanovyordan'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1faffxt/share_your_dotfiles/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faffxt/share_your_dotfiles/', 'subreddit_subscribers': 210878, 'created_utc': 1725629979.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.894+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'doing some research on MongoDB and other databases, curious to know where you guys face challenge with MongoDB?\n\n[View Poll](https://www.reddit.com/poll/1faaxdg)', 'author_fullname': 't2_y0in31xr4', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Challenges with MongoDB', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faaxdg', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725614719.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>doing some research on MongoDB and other databases, curious to know where you guys face challenge with MongoDB?</p>\n\n<p><a href="https://www.reddit.com/poll/1faaxdg">View Poll</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1faaxdg', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='biz-guru-3112'), 'discussion_type': None, 'num_comments': 16, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'poll_data': <praw.models.reddit.poll.PollData object at 0xffff91b91d60>, 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faaxdg/challenges_with_mongodb/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'mod_reports': [], 'url': 'https://www.reddit.com/r/dataengineering/comments/1faaxdg/challenges_with_mongodb/', 'subreddit_subscribers': 210878, 'created_utc': 1725614719.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.894+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff91c5cd00>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "So how can i build robust data strategy that use best data engineering practices to maintain vaule over time .\n\nWhat's the step ? \nHow to build data modeling milestones etc ?", 'author_fullname': 't2_vomfw03h', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Data strategy', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1faeorw', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.45, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1725627896.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>So how can i build robust data strategy that use best data engineering practices to maintain vaule over time .</p>\n\n<p>What&#39;s the step ? \nHow to build data modeling milestones etc ?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1faeorw', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='AShmed46'), 'discussion_type': None, 'num_comments': 13, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1faeorw/data_strategy/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1faeorw/data_strategy/', 'subreddit_subscribers': 210878, 'created_utc': 1725627896.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-07T03:07:19.895+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-09-07T03:07:19.896+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-09-07T03:07:19.907+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=elt_reddit_pipeline, task_id=reddit_extraction, run_id=manual__2024-09-07T03:07:17.869062+00:00, execution_date=20240907T030717, start_date=20240907T030718, end_date=20240907T030719
[2024-09-07T03:07:19.958+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 0
[2024-09-07T03:07:19.973+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-09-07T03:07:19.974+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
